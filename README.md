# Fine-tune LLaMA 2 (7B) with LoRA on meta-math/MetaMathQA
Fine-tuning and Inference codes on the MetaMath Dataset

  |       Epoch       | Accuracy on the testing set | Model Link |
  |:---:|:----:|:----:|
  | 1 | 0.609 | ðŸ¤— [Hugging Face](https://huggingface.co/shuyuej/metamath_lora_llama2_7b) |
  | 2 | 0.635 | ðŸ¤— [Hugging Face](https://huggingface.co/shuyuej/metamath_lora_llama2_7b_2_epoch)  |
  | 3 | 0.641 | ðŸ¤— [Hugging Face](https://huggingface.co/shuyuej/metamath_lora_llama2_7b_3_epoch) |
  | 4 | 0.641 | ðŸ¤— [Hugging Face](https://huggingface.co/shuyuej/metamath_lora_llama2_7b_4_epoch) |
